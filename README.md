# MCD-LABIII







##Informe Final - Laboratorio III
##2025



Integrantes
		
		
Mart√≠n Salamero
Ana Laura Ruibal Conti


CONTENIDOS


1. Qu√© probamos y los resultados	2
2. Qu√© no funcion√≥	3
3. Modelo final seleccionado (AutoGluon)	4
‚óã Procesamiento de los datos	5
‚óã Ingenier√≠a de Caracter√≠sticas	5
‚óã Configuraci√≥n del Modelo	5
4. Conclusi√≥n	6
5. Repositorio GitHub	6


Qu√© probamos y los resultados
Durante la cursada se evaluaron m√∫ltiples enfoques para resolver el problema propuesto en Kaggle. Las pruebas incluyeron:
Modelos base como AutoArima y SARIMAX
Modelos m√°s avanzados como LightGBM 
Modelos autom√°ticos como AutoGluon 



Qu√© no funcion√≥
Los modelos cl√°sicos de series temporales (ARIMA y SARIMAX) no lograron un buen rendimiento en esta competencia. Aunque el tiempo de entrenamiento fue algo positivo, sus resultados fueron inferiores al promedio. Asimismo en un enfoque con LightGBM no logramos buenos resultados, siendo cada una de las pruebas muy costosas en lo relativo a tiempo de ejecuci√≥n. Es por ello que decidimos abordar AutoGluon como una posible soluci√≥n.
AutoGluon fue el modelo con mejor desempe√±o general acompa√±ado de corto tiempo de entrenamiento y baja demanda computacional. Para mejorar su desempe√±o hicimos algunas intervenciones. Debajo se describen aquellas  no aportaron mejoras sustanciales: 
Imputaci√≥n de Valores Faltantes (NaNs)
Para completar las series temporales se aplicaron las siguientes estrategias de imputaci√≥n manual:
Promedio por producto (product_id)
Ceros antes del primer dato y promedio despu√©s
Interpolaci√≥n lineal
Ceros antes del primer dato e interpolaci√≥n despu√©s
La imputaci√≥n del promedio fue la que mostr√≥ una leve mejora en el rendimiento. Sin embargo, el preprocesamiento manual no aport√≥ beneficios significativos dentro del flujo autom√°tico de AutoGluon, que demostr√≥ ser m√°s eficiente gestionando internamente los valores faltantes.
Por ello, se evaluaron tambi√©n los m√©todos incorporados en la funci√≥n fill_missing_values() de TimeSeriesDataFrame. Esta funci√≥n ofrece cinco opciones: "auto", "ffill", "bfill", "constant" e "interpolate". La configuraci√≥n por defecto ("auto") result√≥ ser la m√°s efectiva. Las dem√°s opciones no generaron mejoras notables en el desempe√±o del modelo.
Ingenier√≠a de Caracter√≠sticas y Validaci√≥n
Se intent√≥ usar como variable objetivo el valor de la serie dos pasos en el futuro (T‚Çô‚Çä‚ÇÇ). Tambi√©n se prob√≥ una validaci√≥n manual: se entren√≥ el modelo con datos desde enero de 2017 hasta agosto de 2019, se evalu√≥ con datos de septiembre y octubre de 2019 y luego se predijo. Los puntajes obtenidos fueron 0.310 y 0.307, sin mejoras relevantes respecto al enfoque autom√°tico.
Ajustes de par√°metros del modelo
El bajo costo computacional de este modelo nos permiti√≥ realizar numerosas pruebas ajustando m√©tricas de evaluaci√≥n, ventanas y dem√°s.
quantile_levels: por defecto pronostica la  "media" ‚Äîes decir, los valores esperados de la serie temporal en el futuro‚Äî como tambi√©n cuantiles de la distribuci√≥n del pron√≥stico. Se utiliz√≥ el cuartil 0.5 (mediana) en lugar de la media para mejorar la robustez de las predicciones.


Estos ajustes, no mejoraron el rendimiento inicial dando scores entre 0.26 y 0.25 




Modelo final seleccionado (AutoGluon)
De todos los modelos evaluados, AutoGluon mostr√≥ el mejor rendimiento general, con tiempos cortos de entrenamiento y baja demanda computacional, por lo que fue seleccionado como modelo final para la competencia

Para correr el modelo se realizaron las siguientes configuraciones
Procesamiento de los datos
Se realiz√≥ con las funciones de TimeSeriesDataFrame/fill_missing_values(auto) 
Ingenier√≠a de Caracter√≠sticas 
Lags, valores previos de una determinada serie de tiempo. Se consideraron valores desde 1 a 6 meses.
Delta lags, diferencia entre los valores de la variable 'lag‚Äô. Tener en cuenta que los extremos no agregan valor por contener todas sus filas nulas.
Medias m√≥viles Promedio de los √∫ltimos per√≠odos consecutivos de la serie temporal. Se consideraron valores de 1 a 3. 
Se agreg√≥ una encuesta de ventas mayorista del Indec para suministrar al modelo tendencias generales del mercado.
https://www.indec.gob.ar/indec/web/Nivel4-Tema-3-1-34https://www.indec.gob.ar/indec/web/Nivel4-Tema-3-1-34

Configuraci√≥n del Modelo

hyperparameters: Se evaluaron tanto los valores por defecto como configuraciones personalizadas.


known_covariates_names: Se incorporaron variables adicionales proporcionadas en el dataset y otras creadas durante el feature engineering.


Conclusi√≥n
El modelo final enviado a Kaggle fue Autogluon. Fue elegido porque:
Obtuvo el mejor rendimiento de todos los modelos que probamos.


Tuvo bajo tiempo de entrenamiento comparado con otros modelos complejos.


Se comport√≥ bien con datos faltantes y las series temporales incompletas evitando largos tiempos de preparaci√≥n del dataset. 
El enfoque basado en AutoGluon con ingenier√≠a de caracter√≠sticas dirigida (lags + macro INDEC) redujo el error de 0.305 a 0.242 SMAPE (‚àí20.8% relativo), con baja complejidad operativa (entrenamiento ‚âà 18 minutos). La automatizaci√≥n interna de imputaciones evit√≥ preprocesamiento manual costoso y permiti√≥ iteraciones r√°pidas. El modelo final que obtuvo mejor m√©trica en en el Autogluon y por lo tanto el utilizado para la preducci√≥n fue WeightedEnsemble, el cual ofrece un balance adecuado entre precisi√≥n y tiempo y sienta una base extensible para incorporar nuevas covariantes y jerarqu√≠as.

Repositorio GitHub
Todo el trabajo realizado se encuentra documentado en el siguiente repositorio:
üîóhttps://github.com/msalamero/MCD-LABIII/tree/main








